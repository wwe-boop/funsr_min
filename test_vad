import random
import numpy as np
import torch
from aimet_torch.quantsim import QuantizationSimModel
from aimet_common.defs import QuantScheme
from vad_funasr import AutoModel
import os
import onnxruntime as ort


def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


# 设置随机种子
set_seed()

# 设备配置
device = 'cpu'
print(f"使用设备: {device}")

# 创建模型
model_wrapper = AutoModel(model='./fsmn_model', device=device)
model = model_wrapper.model

# 测试原始模型
print("测试原始模型...")
test_wav = 'fsmn_model/example/vad_example.wav'
original_result = model_wrapper.inference(test_wav)
print(f"原始模型结果: {original_result}")


# 准备评估函数
def eval_func_quant(model, args):
    """用于量化校准的评估函数"""
    batch_size, use_cuda = args
    test_wav = 'fsmn_model/example/vad_example.wav'  # 修正音频路径

    # 使用模型进行推理
    try:
        # 直接使用随机生成的特征进行评估
        # 这样可以避免特征提取过程中的错误
        feats = torch.rand(1, 100, 400).to(device)  # 使用与dummy_input相同的形状
        
        # 前向传播
        with torch.no_grad():
            outputs = model(feats)

        return outputs
    except Exception as e:
        print(f"评估函数执行失败: {e}")
        import traceback
        traceback.print_exc()
        return None


# 准备量化配置
config_file = 'config_for_eai.json'
quant_scheme = QuantScheme.post_training_tf_enhanced

# 准备示例输入
# 根据日志中显示的实际输入维度进行调整
dummy_input = torch.rand(1, 100, 400).to(device)  # [batch_size, sequence_length, feature_dim]
dummy_waveform = torch.rand(1, 16000).to(device)  # 假设1秒的音频，采样率16kHz

# 创建量化模拟模型
print("创建量化模拟模型...")
# 创建一个更简单的包装模型
class SimpleModelWrapper(torch.nn.Module):
    def __init__(self, model):
        super().__init__()
        self.encoder = model.encoder  # 只使用编码器部分
    
    def forward(self, x):
        # 直接使用编码器，跳过复杂的缓存和检测逻辑
        return self.encoder(x)

wrapped_model = SimpleModelWrapper(model)

sim = QuantizationSimModel(model=wrapped_model,
                           dummy_input=dummy_input,
                           quant_scheme=quant_scheme,
                           default_param_bw=8,
                           default_output_bw=16,
                           config_file=config_file)

# 计算编码
print("计算量化编码...")
sim.compute_encodings(eval_func_quant, (1, device == 'cpu'))

# 测试量化模型
print("测试量化模型...")
try:
    # 使用随机生成的特征进行测试
    feats = torch.rand(1, 100, 400).to(device)
    
    # 前向传播
    with torch.no_grad():
        quant_outputs = sim(feats)
    
    print(f"量化模型输出形状: {quant_outputs.shape}")
except Exception as e:
    print(f"量化模型测试失败: {e}")
    import traceback
    traceback.print_exc()

# 导出量化模型到ONNX
print("导出量化模型到ONNX...")
output_dir = "quantized_model_dir"
os.makedirs(output_dir, exist_ok=True)

# 设置ONNX导出参数
from aimet_torch.onnx_utils import OnnxExportApiArgs  # 添加缺失的导入
onnx_export_args = OnnxExportApiArgs(opset_version=11)

# 导出模型
sim.export(path=output_dir,
           filename_prefix='quantized_vad_model',
           dummy_input=dummy_input,  # 使用正确维度的dummy_input
           onnx_export_args=onnx_export_args)

print(f"量化模型已导出到: {output_dir}/quantized_vad_model.onnx")

# 验证导出的ONNX模型
print("验证ONNX模型...")
onnx_path = f"{output_dir}/quantized_vad_model.onnx"
try:
    # 首先尝试使用onnx库加载和检查模型
    import onnx
    onnx_model = onnx.load(onnx_path)
    onnx.checker.check_model(onnx_model)
    print("ONNX模型结构验证成功!")
    
    # 然后尝试使用onnxruntime加载模型
    ort_session = ort.InferenceSession(onnx_path)
    print("ONNX模型加载成功!")

    # 获取输入名称
    input_name = ort_session.get_inputs()[0].name
    
    # 准备ONNX输入 - 使用随机数据
    test_input = np.random.rand(1, 100, 400).astype(np.float32)
    onnx_input = {input_name: test_input}

    # 运行ONNX模型
    onnx_outputs = ort_session.run(None, onnx_input)

    print(f"ONNX模型输出形状: {onnx_outputs[0].shape}")
    print("ONNX模型验证成功!")
except Exception as e:
    print(f"ONNX模型验证失败: {e}")
    import traceback
    traceback.print_exc()

print("量化过程完成!")














